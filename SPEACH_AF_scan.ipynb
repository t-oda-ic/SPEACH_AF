{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPEACH_AF_SCAN\n",
    "#### Sampling Protein Ensembles and Conformational Heterogeneity with Alphafold2\n",
    "***\n",
    "This notebook will take as input an MSA (a3m format) and a protein structure (pdb format) that were generated by an initial ColabFold run and generate modified MSAs with alanine mutagenesis.\n",
    "Requires: Bio, numpy, and copy\n",
    "\n",
    "Inputs needed:\n",
    "> the a3m file and the pdb file (path and fullname) <br>\n",
    "> the output directory (needs the final slash and already exist) <br>\n",
    "> the basename for the MSA output\n",
    "\n",
    "Adjustable variables:\n",
    "> the size of the sliding window <br>\n",
    "> the number of repeats per sliding window <br>\n",
    "> the proximity in angstrom for the interacting residues <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3m_filename = ''         # MSA file in a3m format\n",
    "pdb_filename = ''         # pdb file\n",
    "output_dir = ''           # directory for the output\n",
    "output_base = ''          # base filename for the output MSAs\n",
    "window = 10               # the size of the sliding window\n",
    "no_out = 3                # the numner of repeats for each window\n",
    "proximity = 4             # interaction size in angstroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import MutableSeq\n",
    "from Bio.Seq import Seq\n",
    "import Bio.PDB as BP\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# read in pdb\n",
    "parser = BP.PDBParser()\n",
    "data = parser.get_structure('mod',pdb_filename)\n",
    "model = data.get_models()\n",
    "models = list(model)\n",
    "chains = list(models[0].get_chains())\n",
    "residue = list(chains[0].get_residues())\n",
    "\n",
    "# get all atom positions\n",
    "positions = []\n",
    "residue_list = []\n",
    "nor = len(residue)\n",
    "for m in range(nor):\n",
    "    atoms = list(residue[m].get_atoms())\n",
    "    noa = len(atoms)\n",
    "    for n in range(noa):\n",
    "        residue_list = np.append(residue_list,residue[m].get_full_id()[3][1])\n",
    "        positions.append(atoms[n].get_vector().get_array())\n",
    "\n",
    "# calculate the distance matrix for all atoms        \n",
    "nop = len(positions)\n",
    "pdist = np.zeros([nop,nop])\n",
    "for m in range(nop):\n",
    "    temp = positions[m]-positions\n",
    "    pdist[m,:] = np.sqrt(temp[:,0]**2+temp[:,1]**2+temp[:,2]**2)\n",
    "\n",
    "# determine the residues to scan over and the interacting partners and write to file\n",
    "b_factor = []\n",
    "resindex = [];\n",
    "for m in range(0,nor):\n",
    "    if residue[m].has_id(\"CA\"):\n",
    "        CA = residue[m][\"CA\"]\n",
    "        b_factor.append(CA.get_bfactor())\n",
    "        resindex.append(residue[m].get_full_id()[3][1])\n",
    "mb = np.mean(b_factor)\n",
    "test = np.where(b_factor > mb)[0]\n",
    "nor = test[-1]-test[0]\n",
    "start = resindex[test[0]];\n",
    "res_no, res_rem = divmod(nor,window)\n",
    "res_use = []\n",
    "f = open(output_dir + output_base + '.txt','w')\n",
    "f.write('{} - {}\\n'.format(test[0],test[-1]))\n",
    "for p in range(0,res_no):\n",
    "    res_to_use = []\n",
    "    min_res = p*window+start\n",
    "    max_res = p*window+start+window\n",
    "    min_res_pos = np.where(residue_list[:] == min_res)[0][0]\n",
    "    max_res_pos = np.where(residue_list[:] == max_res)[0][-1]\n",
    "    for m in range(min_res_pos,max_res_pos):\n",
    "        temp_dist = np.where(pdist[m,:] < proximity)[0]\n",
    "        for n in range(len(temp_dist)):\n",
    "            temp_res = np.int(residue_list[temp_dist[n]])\n",
    "            if not(min_res-4 <= temp_res <= max_res+4):\n",
    "                res_to_use.append(np.int(residue_list[m]))\n",
    "                res_to_use.append(temp_res)\n",
    "    res_to_use = np.unique(res_to_use).tolist()\n",
    "    res_use.append(res_to_use)\n",
    "    f.write('{:02} -- {}-{}: {}\\n'.format(p+1,min_res,max_res,res_to_use))\n",
    "for p in range(res_no,res_no+1):\n",
    "    res_to_use = []\n",
    "    min_res = max_res+1\n",
    "    max_res = min_res+res_rem-1\n",
    "    min_res_pos = np.where(residue_list[:] == min_res)[0][0]\n",
    "    max_res_pos = np.where(residue_list[:] == max_res)[0][-1]\n",
    "    for m in range(min_res_pos,max_res_pos):\n",
    "        temp_dist = np.where(pdist[m,:] < proximity)[0]\n",
    "        for n in range(len(temp_dist)):\n",
    "            temp_res = np.int(residue_list[temp_dist[n]])\n",
    "            if not(min_res-4 <= temp_res <= max_res+4):\n",
    "                res_to_use.append(np.int(residue_list[m]))\n",
    "                res_to_use.append(temp_res)\n",
    "    res_to_use = np.unique(res_to_use).tolist()\n",
    "    res_use.append(res_to_use)\n",
    "    f.write('{:02} -- {}-{}: {}\\n'.format(p+1,min_res,max_res,res_to_use))\n",
    "f.close()    \n",
    "\n",
    "# read in MSA\n",
    "# check for hashtag on first line\n",
    "f = open(a3m_filename,'r')\n",
    "first = f.readline()\n",
    "f.close()\n",
    "if first[0] == '#':\n",
    "    hash_there = True\n",
    "else:\n",
    "    hash_there = False\n",
    "records = list(SeqIO.parse(a3m_filename, \"fasta\"))\n",
    "\n",
    "# save unmodified MSA\n",
    "alidatac = copy.deepcopy(records)\n",
    "lines = []\n",
    "nos = len(alidatac);\n",
    "los = len(alidatac[0].seq);\n",
    "lines_no, remainder = divmod(los,100)\n",
    "for m in range(0,nos):\n",
    "    lines.append('>'+alidatac[m].description+'\\n')\n",
    "    n = -1; #if lines_no == 0, n = len(temp_dist)\n",
    "    for n in range(0,lines_no):\n",
    "        lines.append(alidatac[m].seq[n*100:(n+1)*100].__str__().upper()+'\\n')\n",
    "    lines.append(alidatac[m].seq[(n+1)*100:(n+1)*100+remainder].__str__().upper()+'\\n')\n",
    "out = \"\".join(lines)\n",
    "for n in range(0,no_out):\n",
    "    output_file = output_dir + output_base + '_{:02}_{:02}.a3m'.format(0,n+1)\n",
    "    if hash_there:\n",
    "        f = open(output_file,'w')\n",
    "        f.writelines(first)\n",
    "        f.close()\n",
    "    with open(output_file,\"a\") as tmp_upload:\n",
    "        tmp_upload.writelines(out)\n",
    "\n",
    "# step over sliding window and change MSA\n",
    "for p in range(0,res_no+1):\n",
    "    res_c = np.array(res_use[p])\n",
    "    no_res = len(res_c)\n",
    "    change_to = ''\n",
    "    for m in range(0,no_res):\n",
    "        change_to += 'A'\n",
    "    alidatac = copy.deepcopy(records)\n",
    "    nos = len(alidatac);\n",
    "    los = len(alidatac[0].seq);\n",
    "    lines = []\n",
    "    lines_no, remainder = divmod(los,100)\n",
    "    for m in range(0,nos):\n",
    "        temp = alidatac[m].seq.__str__()\n",
    "        ltemp = len(temp);\n",
    "        words = zip(temp[0:].upper(),temp[0:])\n",
    "        isup = [int(i==j) for i,j in words]\n",
    "        count = 0;\n",
    "        for n in range(0,ltemp):\n",
    "            count = count + isup[n];\n",
    "            if np.isin(count,res_c):\n",
    "                inds = np.where(res_c == count)[0][0]\n",
    "                if temp[n] != '-':\n",
    "                    temp = temp[:n] + change_to[inds] + temp[n+1:]\n",
    "        alidatac[m].seq = Seq(temp);\n",
    "    \n",
    "        lines.append('>'+alidatac[m].description+'\\n')\n",
    "        n = -1; # if lines_no == 0, n = ltemp-1\n",
    "        for n in range(0,lines_no):\n",
    "            lines.append(alidatac[m].seq[n*100:(n+1)*100].__str__().upper()+'\\n')\n",
    "        lines.append(alidatac[m].seq[(n+1)*100:(n+1)*100+remainder].__str__().upper()+'\\n')\n",
    "\n",
    "    out = \"\".join(lines)\n",
    "    for n in range(0,no_out):\n",
    "        output_file = output_dir + output_base + '_{:02}_{:02}.a3m'.format(p+1,n+1)\n",
    "        if hash_there:\n",
    "            f = open(output_file,'w')\n",
    "            f.writelines(first)\n",
    "            f.close()\n",
    "        with open(output_file,\"a\") as tmp_upload:\n",
    "            tmp_upload.writelines(out)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License\n",
    "This notebook and source code is licensed under MIT.\n",
    "***\n",
    "Aug. 22, 2022 Richard Stein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
